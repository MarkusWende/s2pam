# Acoustic model for speech-to-phone conversion

### Abstract (from thesis)
The development of speech recognition systems has been favored not only by the use of artificial neural networks (ANNs) in research and computer vision, but also by the use of speech recognition software in consumer products such as mobile phones, automobiles and televisions. Recurrent Neural Networks (RNNs) and Bidirectional Long Short Term Memory (BLSTM) in particular, represent one type of Neural Network (NN), which is well suited for speech classification, because of the ability to maintain its state over time. In this thesis an Acoustic Model (AM) for phone recognition in speech based on a BLSTM architecture is developed and written in the programming language C++. Training and evaluation of the AM is done by using the TIMIT Acoustic-Phonetic Continuous Speech Corpus and the results are compared with outcomes of recent phone recognition algorithms. Motivation for the development was the need for a tool that can quickly and efficiently classify phones in an audio stream. Thus, an accuracies of $26.6\%$ in the classification of phones could be achieved. Because it was ensured that the developed AM is also easy to adapt, other label groups were also classified. For example, an accuracy of $70.0\%$ in classifying articulations and in classifying vowels and consonants an accuracy of $75.2\%$ could be achieved. These results show that the developed software, for the existing time, provides good results and as a proof-of-concept offers the possibility to join further experiments in the future.
